[toc]

# 整体检查步骤

1. 进行现场资源检查，是否与知识库匹配（访问地址，服务器密码等； 需业务配合）
2. 检查 和宇云版本(需为3.1.6最终版)， 脚本pyscript，springboot，yum源的版本情况(需为最新)
3. 检查 csb的网关redis是不是单独部署的，如果不是，需要额外申请服务器通过adm进行部署（主从+keepalived）
4. 检查中间件的部署节点数量，fdfs-tacker=3, redis集群=3主3从或者3主，redis-proxy=1主1从+keepalived，kafka集群=3kafka+3zk
5. 检查中间件是不是都是通过adm部署的（包括： 业务redis，kafka+zk，fastDFS，csb的redis）
6. 检查adm部署中间件的实例名称，为便于在构建灾备组时进行选择，需填写为易于区分的名称(如:易联众-公共服务子系统Redis-A)
7. 检查中间件部署模式，例如redis集群，redis主从高可用，kafka部署模式，文件存储部署模式。各产品都必须要部署至adm一个实例里面
8. 检查双中心容灾构建时A中心必要的组件，power-dns，bind域名解析，power-api
9. 核对DNS的biz.powercloud.com相关域名的配置情况(需要与PowerADM实例中生成的域名一致，不一致需要修改DNS中的域名记录)
10. 检查业务连接配置是否通过域名进行连接（未配置域名连接，需要我们提供相关连接信息，业务配合进行配置中心修改、发布以及应用重启)
11. csb或者业务的isp中的服务管理中，是否满足双中心切换，服务方位地址需配置为域名。无域名需要通过adm生成对应域名加入到DNS中，并在服务管理进行修改与发布



# 西藏前置处理

1. 进行现场资源检查，是否与知识库匹配（访问地址，服务器密码等； 需业务配合）

   ```
   1. PaaS平台资源基本核对正确，访问地址，服务器密码也OK
   2. * 业务资源需业务配合核对
   ```

2. 检查 和宇云版本(需为3.1.6最终版)， 脚本pyscript，springboot，yum源的版本情况(需为最新) 

   ```tex
   1. * PaaS平台部署的jar包版本是2021年6月份的版本，需要更新最新3.1.6的包
   2. * pyscript为2021六月份的，非最新版本，需升级
   3. * springboot版本与湖南不相同，但是仔细比较了一下，只是在应用停止的脚本中有些改变，所以只需要升级springboot的脚本，业务应用可以不需要重启(通过新版pypssh)
   	备份源SPRINGBOOT目录
   	pypssh -t paas execute -c "mv /app/soft/deploy/SPRINGBOOT/ /app/soft/deploy/SPRINGBOOT_BAK/ && mkdir /app/soft/deploy/SPRINGBOOT/" -o template
   	上传SPRINGBOOT压缩包
   	pypssh -t paas put /root/springboot_2.0.x.zip /app/soft/deploy/SPRINGBOOT/springboot_2.0.x.zip -o template
   解压
   	pypssh -t paas execute -c "unzip /app/soft/deploy/SPRINGBOOT/springboot_2.0.x.zip -d /app/soft/deploy/SPRINGBOOT/" -o template
   	修改权限
   	pypssh -t paas execute -c "chown app.app -R /app/soft/deploy/SPRINGBOOT/" -o template
   4. * yum源需要上传最新的tar.gz进行更新
   (更新完以上几点后，需对云平台几个应用进行配置，启停；确保正常能执行)
   ```

3. 检查 csb的网关redis是不是单独部署的，如果不是，需要额外申请服务器通过进行部署(主从+keepalived)

    ```
    1. * 网关csb的redis是单独部署的，需要adm重新安装(同业务中间件重装一并进行)
    ```

4. 检查中间件的部署节点数量，fdfs-tacker=3, redis集群=3主3从或者3主，redis-proxy=1主1从+keepalived，kafka集群=3kafka+3zk

    ```shell
    1. tarker只存在两台,需要添加一台tracker
    2. redis都是主从高可用，不涉及到集群，满足节点数量要求
    3. kafka+zk是三节点，满足节点数量要求
    ```

    

5. 检查中间件是不是都是通过adm部署的（包括： 业务redis，kafka+zk，fastDFS，csb的redis）

    ```
    否，需要全部通过adm部署
    ```
    
6. 产出《业务的中间件资源情况》文档，将文档发与予业务进行核实中间件是否与实际安装，使用的中间件一致。

    具体的中间件的部署服务器，账号密码。以及现场使用的情况文档记录

    

# 中间件的升级过程

目前西藏中间件只包含，redis、kafka、fastdfs

**Redis**

1. 首先拿到现有主从redis的vip和密码

   ```shell
   cat /etc/redis/redis.conf
   #寻找到密码配置，保存好，后续自动部署需要使用
   ```

2. 进入redis进行SAVE，持久化数据，停止redis和keepalived进程

   ```shell
   # 【主】上执行
   /app/soft/redis-5.0.5/bin/redis-cli -a 密码
   #进入redis客户端,持久化rdb文件（主上执行）
   SAVE
   # 【主】【从都执行】
   service redis stop
   service keepalived stop
   ```

3. 备份redis和keepalived的目录,以及service文件(/etc/对应文件目录)

   ```shell
   #二进制目录
   mv /app/soft/redis-5.0.5 /app/soft/redis-5.0.5_bak
   mv /app/soft/keepalived /app/soft/keepalived_bak
   mv /etc/init.d/redis /etc/init.d/redis_bak
   mv /etc/init.d/keeplived /etc/init.d/keeplived_bak
   mv /app/redis_data /app/redis_data_bak
   #配置文件
   mv /etc/redis/redis.cnf /etc/redis/redis.cnf_bak
   mv /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf_bak
   #service 文件
   mv /etc/init.d/redis /etc/init.d/redis_bak
   mv /etc/init.d/keepalived /etc/init.d/keepalived_bak
   ```

4. adm界面安装主从高可用redis(密码和vip不变，用原来的)

5. 停止redis主将备份的rdb文件放置对应新安装的redis目录下，启动

   ```shell
   a. 由于vesta守护作用，需要将redis的目录先mv，不让vesta守护(先从执行，再主执行)
   mv /app/soft/redis /app/soft/redis_bak
   systemctl stop redis
   
   b. 【主】上执行
   cp /app/redis_data_bak/rdb.dump /app/redis_data/
   
   c. 先在【主】执行，再到【从】执行
   mv /app/soft/redis_bak /app/soft/redis
   systemctl start redis
   ```

6. 回退操作

   ```shell
   (1).通过adm界面卸载实例
   (2).将备份目录还原
   #二进制目录
   mv /app/soft/redis-5.0.5_bak /app/soft/redis-5.0.5
   mv /app/soft/keepalived_bak /app/soft/keepalived
   mv /etc/init.d/redis_bak /etc/init.d/redis
   mv /etc/init.d/keeplived_bak /etc/init.d/keeplived
   mv /app/redis_data_bak /app/redis_data
   #配置文件
   mv /etc/redis/redis.cnf_bak /etc/redis/redis.cnf
   mv /etc/keepalived/keepalived.conf_bak /etc/keepalived/keepalived.conf
   #service 文件
   mv /etc/init.d/redis_bak /etc/init.d/redis
   mv /etc/init.d/keepalived_bak /etc/init.d/keepalived
   (3).启动中间件
   service redis start
   service keepalived start
   ```

**kafka**

1. 确保停机一段时间之后，kafka中无残留消息，停掉zk和kafka进程

   ```shell
   service kafka stop
   service zookeeper stop
   ```

2. 备份zookeeper和kafka对应目录,对应/etc目录下service文件

   ```shell
   mv /app/soft/apache-zookeeper-3.5.6-bin /app/soft/apache-zookeeper-3.5.6-bin_bak
   mv /app/soft/kafka_2.12-2.3.0 /app/soft/kafka_2.12-2.3.0_bak
   mv /etc/init.d/zookeeper /etc/init.d/zookeeper_bak
   mv /etc/init.d/kafka /etc/init.d/kafka_bak
   ```

3. 通过adm进行重新部署，zk和kafka

4. 回退操作

   ```shell
   (1).通过adm界面卸载实例
   (2).将备份目录还原
   mv /app/soft/apache-zookeeper-3.5.6-bi_bak /app/soft/apache-zookeeper-3.5.6-bin
   mv /app/soft/kafka_2.12-2.3.0_bak /app/soft/kafka_2.12-2.3.0
   mv /etc/init.d/zookeeper_bak /etc/init.d/zookeeper
   mv /etc/init.d/kafka_bak /etc/init.d/kafka
   (3).启动中间件
   service kafka start
   service zookeeper start
   ```

**fastDFS**

#重点说明

```
文件存储安装的是两台tracker,安装的两台tracker上面分别还安装的storage 和 fdfs模块的nginx,我检查，安装的storage是没有存储文件的，数据录加起来也就2.3M。所有通过adm部署的时候，只要在3台(原来两台再添加一台)上面部署tarcker,外加两个nginx来专门做文件下载的负载(是需要vip的)。
storage的数据存储目录，log目录和pid文件是分开的，adm是全部都放到/mysql下了
```

1. 停掉进程(tracker)

   ```shell
   service trackerd stop
   ```

2. 备份fdfs(tracker)的目录

   ```shell
   #公共区现有两台tracker，另加一台172.26.148.4
   #公共区现有两台tracker，另加一台172.26.20.21
   mv /app/tracker /app/tracker_bak
   mv /etc/init.d/fdfs_trackerd /etc/init.d/fdfs_trackerd_bak
   ```

3. 通过adm进行重新部署三节点tracker实例(需部署在一个实例里面)

   ```shell
   需要将原目录 /app/tracker下的两个文件夹cp至/mysql/fastdfs/tracker_base(tracker的日志以及pid文件)
   systemctl restart trackerd
   ```

4. 依次停止一套storaged进程(storaged,nginx),需要一套一套升级

   ```shell
   service storaged stop
   service nginx stop
   ```

5. 备份fdfs(storaged ,nginx)的目录，并且记录group，桶名

   ```
   mv /app/storage /app/storage_bak
   mv /usr/local/nginx  /usr/local/nginx_bak
   
   mv /etc/init.d/fdfs_storaged /etc/init.d/fdfs_storaged_bak
   mv /etc/init.d/nginx /etc/init.d/nginx_bak
   ```

6. adm部署完成以后，将文件存储目录移动到新部署的storaged存储目录中。启动

   ```shell
   需要将原目录 /app/storage/下的两个文件夹cp至/mysql/fastdfs/storage_base(storage的日志以及pid文件)
   需要将原目录 /mysql/storage0/data 下的两个文件夹cp至/mysql/fastdfs/storage/data(存储的文件)
   systemctl restart storaged
   systemctl restart nginx
   ```

7. 回退操作

   ```shell
   (1).通过adm界面卸载实例
   (2).将备份目录还原
   mv /app/tracker_bak /app/tracker
   mv /etc/init.d/fdfs_trackerd_bak /etc/init.d/fdfs_trackerd
   
   mv /app/storage_bak /app/storage
   mv /usr/local/nginx_bak  /usr/local/nginx
   
   mv /etc/init.d/fdfs_storaged_bak /etc/init.d/fdfs_storaged
   mv /etc/init.d/nginx_bak /etc/init.d/nginx
   (3).启动中间件
   service trackerd start
   service storaged start
   service nginx start
   ```

      

# 核查的过程



1. 检查中间件部署模式，例如redis集群，redis主从高可用，kafka部署模式，文件存储部署模式。各产品都必须要部署至adm一个实例里面

   ```
   目前已经根据知识库整理一个文档，西藏现场中间件都需要重新部署，部署时注意即可
   ```

2. 检查adm部署中间件的实例名称，为便于在构建灾备组时进行选择，需填写为易于区分的名称(如:易联众-公共服务子系统Redis-A)

   ```
   现场核对以后，通过现场给的名字部署实例名称
   ```

3. 检查双中心容灾构建时A中心必要的组件，power-dns，bind域名解析，power-api

   ```tex
   power-dns已经部署
   bind域名解析中间件已经部署
   power-api未部署，需规划
   ```

4. 核对DNS的biz.powercloud.com相关域名的配置情况(需要与PowerADM实例中生成的域名一致，不一致需要修改DNS中的域名记录)

5. 检查业务连接配置是否通过域名进行连接（未配置域名连接，需要我们提供相关连接信息，业务配合进行配置中心修改、发布以及应用重启)

6. csb或者业务的isp中的服务管理中，是否满足双中心切换，服务方位地址需配置为域名。无域名需要通过adm生成对应域名加入到DNS中，并在服务管理进行修改与发布